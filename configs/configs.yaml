General:
  seed: 0
  num_devices: -1
  check_val_every_n_epoch: 1 # number of epochs between validation check, needs to be empty (None) for using #batches
  val_check_interval: 0.25 # number of training batches between each validation check
  num_sanity_val_steps: 0
  log_every_n_steps: False
  fast_dev_run: False
  profiling: False
  inference_mode: True
  version:  # could be either a string or None, in which case the version is automatically generated


Model:
  model_type: expert # could be either 'analytics' or 'expert' or 'jpeg' or 'moe' or 'fusion'
  classifier: resnet50 # 'mislnet' or 'resnet50'
  expert_ckpt: logs/expert_resnet50_db-real_db-gan_src_q99/version_10/checkpoints/epoch=25-step=12194-v_loss=0.1221-v_acc=0.9588.ckpt
  analytics_ckpt: logs/ft_analytics_dn-real_du-gan_dn-sd_jpeg_q99/version_0/checkpoints/epoch=19-step=940-v_loss=0.2655-v_acc=0.8892.ckpt
  moe_ckpt: logs/moe_dn-real-500_dn-gan-500_dn-tt_dn-sd-500_dn-eg3d_dn-dalle2_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.1274-v_acc=0.9522-last.ckpt
  expert_n_features: 200
  fusion_rule: 'max' # could be either 'avg' or 'max'
  fine_tune: False # if True, the model is fine-tuned from a checkpoint
  override_configs: True # if True, the config is overridden with the values in this file, otherwise the config is loaded from the checkpoint
  expert_task: src # could be either 'src' or 'manipulation', 'src_test_with_manipulation'
  src_ckpts: [
    logs/expert_mislnet_db-real_db-gan_src_q99/version_4/checkpoints/epoch=97-step=183750-v_loss=0.0654-v_acc=0.9763.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-sd14_src_q99/version_16/checkpoints/epoch=149-step=2400-v_loss=0.3417-v_acc=0.8800-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-glide_src_q99/version_9/checkpoints/epoch=149-step=2400-v_loss=0.0403-v_acc=0.9850-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-mj_src_q99/version_5/checkpoints/epoch=149-step=2400-v_loss=0.6459-v_acc=0.8350-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-dallemini_src_q99/version_2/checkpoints/epoch=149-step=2400-v_loss=0.4711-v_acc=0.8700-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-tt_src_q99/version_2/checkpoints/epoch=149-step=2400-v_loss=0.1787-v_acc=0.9600-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-sd21_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=1.6322-v_acc=0.6300-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-cips_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.0516-v_acc=0.9750-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-biggan_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=4.5514-v_acc=0.5500-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-vqdiff_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.1306-v_acc=0.9700-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-diffgan_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=4.4042-v_acc=0.5200-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-sg3_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.1419-v_acc=0.9700-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-gansformer_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.2388-v_acc=0.9350-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-dalle2_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.0287-v_acc=0.9900-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-ld_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=1.7899-v_acc=0.6800-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-eg3d_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.0053-v_acc=1.0000-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-projgan_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.3961-v_acc=0.8800-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-sd1_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.2472-v_acc=0.9200-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-ddg_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.5158-v_acc=0.9300-last.ckpt,
    logs/ft_expert_mislnet_dn-real_dn-ddpm_src_q99/version_0/checkpoints/epoch=149-step=2400-v_loss=0.5851-v_acc=0.8500-last.ckpt
  ] # list of paths to source classifier checkpoints to be used for analytics model
  manipulation_ckpts: [
    logs/ft_expert_resnet50_dn-real_dn-sd_src_q99/version_0/checkpoints/epoch=59-step=1920-v_loss=0.2927-v_acc=0.8750.ckpt
  ] # list of paths to manipulation classifier checkpoints to be used for analytics model
  fusion_ckpt: 
  jpeg_ckpt: logs/jpeg_midb_q50-100/version_0/checkpoints/epoch=96-step=213885-v_loss=2.5862-v_rmse=0.0000-v_mae=1.7335.ckpt
  analytics_manipulations: ['jpeg'] # list of manipulation names: 'unsharpmask', 'upsample', 'medianblur', 'bilateralblur' only used with analytics model
  expert_manipulation: ['medianblur'] # only used with expert model
  patch_size: 256

Data:
  datasets: [
    'db-real',
    'db-gan',
  ]
  num_src_classes: 2
  train_txt_paths: [
    datasets/final_dataset_paths/db-real/train.txt,
    datasets/final_dataset_paths/db-gan/train.txt,
  ]
  val_txt_paths: [
    datasets/final_dataset_paths/db-real/val.txt,
    datasets/final_dataset_paths/db-gan/val.txt,
  ]
  test_txt_paths: [
    datasets/final_dataset_paths/db-real/test.txt,
    datasets/final_dataset_paths/db-gan/test.txt,
  ]
  train_hdf5_paths: [/media/nas2/misl_image_db_70_class/experimental/256/train.hdf5, "", "", "", "", "", "", ""]
  val_hdf5_paths: [/media/nas2/misl_image_db_70_class/experimental/256/val.hdf5, "", "", "", "", "", "", ""]
  test_hdf5_paths: [/media/nas2/misl_image_db_70_class/experimental/256/test.hdf5, "", "", "", "", "", "", ""]
  jpeg_quality: [99] # only used for training, could be either an int or a list of ints
  test_jpeg_qualities: [99] # only used for testing with different jpeg qualities, should be a list of ints
  randomize_jpeg_quality: False # if True, jpeg_quality is ignored and it's set to list(np.arange(70, 100, 1))
  num_workers: 8
  prefetch_factor: 3

Train:
  epochs: -1
  max_steps: -1
  early_stopping: False
  loss_weights: [1.0, 1.0] # only used with mixture model loss to deal with class imbalance
  batch_size: 64
  lr: 1.0e-4
  src_loss_coeff: 1.0
  manipulation_loss_coeff: 0.0
  accumulate_grad_batches: 1
  scheduler: step # cosine, step
  lr_decay_rate: 0.75 # only used with step scheduler
  lr_step_size: 3 # only used with step scheduler
  min_lr: 1.0e-5 # only used with cosine scheduler
  optimizer: AdamW # Adam, AdamW, SGD
  momentum: 0.9 # only used with SGD optimizer
  train_dataset_hard_limit_num:
  val_dataset_hard_limit_num:
  test_dataset_hard_limit_num:
  train_dataset_limit_per_class: # class refers to either synthetic or real, synthetic is equally 
  val_dataset_limit_per_class: # disributed among the generators
  test_dataset_limit_per_class:
  train_dataset_limit_real:
  val_dataset_limit_real:
  test_dataset_limit_real:
  train_dataset_limit: 1.0
  val_dataset_limit: 1.0
  test_dataset_limit: 1.0
  use_jit: False # if True, analytics model uses torch.jit.fork and torch.jit.wait for training